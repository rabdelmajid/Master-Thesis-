{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['search',\n",
       "  'information',\n",
       "  'relevant',\n",
       "  'search',\n",
       "  'metadata',\n",
       "  'metadata',\n",
       "  'efficiency',\n",
       "  'machine',\n",
       "  'learning,',\n",
       "  'deep',\n",
       "  'learning',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'semantic',\n",
       "  'similarity',\n",
       "  'by',\n",
       "  'efficiency',\n",
       "  'algorithms',\n",
       "  'use',\n",
       "  'algorithms',\n",
       "  'enhance',\n",
       "  'search',\n",
       "  'results',\n",
       "  'on',\n",
       "  'study',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'machine',\n",
       "  'learning,',\n",
       "  'deep',\n",
       "  'learning',\n",
       "  'metadata',\n",
       "  'enhancing',\n",
       "  'search',\n",
       "  'this',\n",
       "  'study',\n",
       "  'as',\n",
       "  'recommender',\n",
       "  'assistance',\n",
       "  'system',\n",
       "  'as',\n",
       "  'relevant',\n",
       "  'information',\n",
       "  'as',\n",
       "  'enhance',\n",
       "  'by',\n",
       "  'documents',\n",
       "  'search',\n",
       "  'study',\n",
       "  'shows',\n",
       "  'enhancing',\n",
       "  'search',\n",
       "  'results',\n",
       "  'by',\n",
       "  'language',\n",
       "  'deep',\n",
       "  'learning,',\n",
       "  'addition,',\n",
       "  'this',\n",
       "  'shows',\n",
       "  'documents',\n",
       "  'can',\n",
       "  'accuracy',\n",
       "  'classifiers',\n",
       "  'such',\n",
       "  'as',\n",
       "  'or',\n",
       "  'deep',\n",
       "  'learning',\n",
       "  'such',\n",
       "  'as',\n",
       "  'accuracy',\n",
       "  'classifiers',\n",
       "  'on',\n",
       "  'addition,',\n",
       "  'semantic',\n",
       "  'similarity',\n",
       "  'words',\n",
       "  'or',\n",
       "  'can',\n",
       "  'by',\n",
       "  'words',\n",
       "  'on',\n",
       "  'system',\n",
       "  'as',\n",
       "  'recommender',\n",
       "  'assistance',\n",
       "  'system',\n",
       "  'use',\n",
       "  'by']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# we'll generate some fake texts to experiment with\n",
    "corpus = [\n",
    "'optimizing analytics Optimization Relevance Context search engine contextual Reputation The massive amount of information published every day has made it difﬁcult to conduct a more relevant search for educational materials, because of loose requirements regarding metadata content. Many researchers have pointed out the importance of metadata and the efficiency of machine learning, deep learning algorithms, and language processing in text classification and semantic similarity by discussing the efficiency of algorithms without indicating how to use these algorithms to enhance search results based on metadata.This study aims to test some of the natural language processing tasks, machine learning, and deep learning techniques, in addition to the role of metadata in enhancing search results. This study propose a framework called \"Al-Quds system\"  as a recommender and assistance system to enables the author to add as much relevant information as possible to their publications to enhance retrievability by increasing the opportunity of displaying documents and texts in the search results.This study shows the possibility of enhancing search results by combining language processing, deep learning, and metadata. In addition, this shows that documents can classified with high accuracy whether using traditional classifiers such as Multinomial Naïve Bayes (MNB) or deep learning such as Convolutional Neural Network (CNN), and the accuracy of classifiers depends primarily on features extracting. In addition, the semantic similarity of words or sentences can computed by representing words into vectors, which had a positive impact on the Al-Quds system as a recommender and assistance system to use by the authors'\n",
    "\n",
    "]\n",
    "\n",
    "# remove stop words and tokenize them (we probably want to do some more\n",
    "# preprocessing with our text in a real world setting, but we'll keep\n",
    "# it simple here)\n",
    "stopwords = set(['for', 'a', 'of', 'the', 'and', 'to', 'in'])\n",
    "texts = [\n",
    "    [word for word in document.lower().split() if word not in stopwords]\n",
    "    for document in corpus\n",
    "]\n",
    "\n",
    "# build a word count dictionary so we can remove words that appear only once\n",
    "word_count_dict = {}\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        word_count = word_count_dict.get(token, 0) + 1\n",
    "        word_count_dict[token] = word_count\n",
    "\n",
    "texts = [[token for token in text if word_count_dict[token] > 1] for text in texts]\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BM25:\n",
    "    \"\"\"\n",
    "    Best Match 25.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    k1 : float, default 1.5\n",
    "\n",
    "    b : float, default 0.75\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    tf_ : list[dict[str, int]]\n",
    "        Term Frequency per document. So [{'hi': 1}] means\n",
    "        the first document contains the term 'hi' 1 time.\n",
    "\n",
    "    df_ : dict[str, int]\n",
    "        Document Frequency per term. i.e. Number of documents in the\n",
    "        corpus that contains the term.\n",
    "\n",
    "    idf_ : dict[str, float]\n",
    "        Inverse Document Frequency per term.\n",
    "\n",
    "    doc_len_ : list[int]\n",
    "        Number of terms per document. So [3] means the first\n",
    "        document contains 3 terms.\n",
    "\n",
    "    corpus_ : list[list[str]]\n",
    "        The input corpus.\n",
    "\n",
    "    corpus_size_ : int\n",
    "        Number of documents in the corpus.\n",
    "\n",
    "    avg_doc_len_ : float\n",
    "        Average number of terms for documents in the corpus.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, k1=1.5, b=0.75):\n",
    "        self.b = b\n",
    "        self.k1 = k1\n",
    "\n",
    "    def fit(self, corpus):\n",
    "        \"\"\"\n",
    "        Fit the various statistics that are required to calculate BM25 ranking\n",
    "        score using the corpus given.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        corpus : list[list[str]]\n",
    "            Each element in the list represents a document, and each document\n",
    "            is a list of the terms.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self\n",
    "        \"\"\"\n",
    "        tf = []\n",
    "        df = {}\n",
    "        idf = {}\n",
    "        doc_len = []\n",
    "        corpus_size = 0\n",
    "        for document in corpus:\n",
    "            corpus_size += 1\n",
    "            doc_len.append(len(document))\n",
    "\n",
    "            # compute tf (term frequency) per document\n",
    "            frequencies = {}\n",
    "            for term in document:\n",
    "                term_count = frequencies.get(term, 0) + 1\n",
    "                frequencies[term] = term_count\n",
    "\n",
    "            tf.append(frequencies)\n",
    "\n",
    "            # compute df (document frequency) per term\n",
    "            for term, _ in frequencies.items():\n",
    "                df_count = df.get(term, 0) + 1\n",
    "                df[term] = df_count\n",
    "\n",
    "        for term, freq in df.items():\n",
    "            idf[term] = math.log(1 + (corpus_size - freq + 0.5) / (freq + 0.5))\n",
    "\n",
    "        self.tf_ = tf\n",
    "        self.df_ = df\n",
    "        self.idf_ = idf\n",
    "        self.doc_len_ = doc_len\n",
    "        self.corpus_ = corpus\n",
    "        self.corpus_size_ = corpus_size\n",
    "        self.avg_doc_len_ = sum(doc_len) / corpus_size\n",
    "        return self\n",
    "\n",
    "    def search(self, query):\n",
    "        scores = [self._score(query, index) for index in range(self.corpus_size_)]\n",
    "        return scores\n",
    "\n",
    "    def _score(self, query, index):\n",
    "        score = 0.0\n",
    "\n",
    "        doc_len = self.doc_len_[index]\n",
    "        frequencies = self.tf_[index]\n",
    "        for term in query:\n",
    "            if term not in frequencies:\n",
    "                continue\n",
    "\n",
    "            freq = frequencies[term]\n",
    "            numerator = self.idf_[term] * freq * (self.k1 + 1)\n",
    "            denominator = freq + self.k1 * (1 - self.b + self.b * doc_len / self.avg_doc_len_)\n",
    "            score += (numerator / denominator)\n",
    "\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.575\toptimizing analytics Optimization Relevance Context search engine contextual Reputation The massive amount of information published every day has made it difﬁcult to conduct a more relevant search for educational materials, because of loose requirements regarding metadata content. Many researchers have pointed out the importance of metadata and the efficiency of machine learning, deep learning algorithms, and language processing in text classification and semantic similarity by discussing the efficiency of algorithms without indicating how to use these algorithms to enhance search results based on metadata.This study aims to test some of the natural language processing tasks, machine learning, and deep learning techniques, in addition to the role of metadata in enhancing search results. This study propose a framework called \"Al-Quds system\"  as a recommender and assistance system to enables the author to add as much relevant information as possible to their publications to enhance retrievability by increasing the opportunity of displaying documents and texts in the search results.This study shows the possibility of enhancing search results by combining language processing, deep learning, and metadata. In addition, this shows that documents can classified with high accuracy whether using traditional classifiers such as Multinomial Naïve Bayes (MNB) or deep learning such as Convolutional Neural Network (CNN), and the accuracy of classifiers depends primarily on features extracting. In addition, the semantic similarity of words or sentences can computed by representing words into vectors, which had a positive impact on the Al-Quds system as a recommender and assistance system to use by the authors\n"
     ]
    }
   ],
   "source": [
    "# query our corpus to see which document is more relevant\n",
    "query = 'Scholar Search Relevancy Optimization'\n",
    "query = [word for word in query.lower().split() if word not in stopwords]\n",
    "\n",
    "bm25 = BM25()\n",
    "bm25.fit(texts)\n",
    "scores = bm25.search(query)\n",
    "\n",
    "for score, doc in zip(scores, corpus):\n",
    "    score = round(score, 3)\n",
    "    print(str(score) + '\\t' + doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
